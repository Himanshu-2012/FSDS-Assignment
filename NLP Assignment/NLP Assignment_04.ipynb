{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35eaef1",
   "metadata": {},
   "source": [
    "#### 1.\tCan you think of a few applications for a sequence-to-sequence RNN? What about a sequence-to-vector RNN? And a vector-to-sequence RNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8008cbaf",
   "metadata": {},
   "source": [
    "Ans.\tIn Sequence to Sequence Learning, RNN is trained to map an input sequence to an output sequence which is not necessarily of the same length. Applications are speech recognition, machine translation, image captioning and question answering. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478edb2",
   "metadata": {},
   "source": [
    "#### 2.\tWhy do people use encoderâ€“decoder RNNs rather than plain sequence-to-sequence RNNs for automatic translation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f11301f",
   "metadata": {},
   "source": [
    "Ans.\tseq-2-seq RNNs translate one word at a time encoder-decoder RNNs read & translate a sentence at a time \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb759d62",
   "metadata": {},
   "source": [
    "#### 3.\tHow could you combine a convolutional neural network with an RNN to classify videos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f56eda3",
   "metadata": {},
   "source": [
    "Ans.\t1. Run a frame from each second of video through a CNN\n",
    "2. Feed CNN outputs as input sequence to RNN\n",
    "3. Feed RNN outputs to softmax layer for probabilities of each class \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639b7b3",
   "metadata": {},
   "source": [
    "#### 4.\tWhat are the advantages of building an RNN using dynamic_rnn() rather than static_rnn()?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb1091",
   "metadata": {},
   "source": [
    "Ans.\t1. avoids out-of-memory errors\n",
    "2. directly takes single tensor as input and output (covering all time steps)\n",
    "3. no need to stack, unstack, or transpose\n",
    "4. generates a smaller easier to visualize graph in TensorBoard \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d0589",
   "metadata": {},
   "source": [
    "#### 5.\tHow can you deal with variable-length input sequences? What about variable-length output sequences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d341e2",
   "metadata": {},
   "source": [
    " Ans.\t1. set sequence_length parameter when calling static_rnn() or dynamic_rnn()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fa3100",
   "metadata": {},
   "source": [
    "#### 6.\tWhat is a common way to distribute training and execution of a deep RNN across multiple GPUs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a928662a",
   "metadata": {},
   "source": [
    "Ans.\tplace each layer on a different GPU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
